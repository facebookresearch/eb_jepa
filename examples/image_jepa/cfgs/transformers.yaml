# Image JEPA (VICReg) Transformers Configuration
# Train a self-supervised image representation model on CIFAR-10 with ViT architectures

meta:
  seed: 42
  device: auto  # auto, cuda, or cpu

data:
  dataset: cifar10
  batch_size: 512
  num_workers: 8

model:
  # Backbone - supports ViT architectures
  type: vit_s         # resnet, vit_s, vit_b
  patch_size: 2       # For ViT only

  # Projector
  use_projector: true
  proj_hidden_dim: 2048
  proj_output_dim: 2048

loss:
  type: vicreg       # vicreg or bcs
  # VICReg loss weights
  std_coeff: 25.0
  cov_coeff: 1.0

optim:
  epochs: 100
  lr: 0.3
  weight_decay: 1.0e-4
  warmup_epochs: 10
  warmup_start_lr: 3.0e-5
  min_lr: 0.0

logging:
  log_wandb: true
  wandb_group:        # Set to group runs (e.g., for seed averaging)
  log_every: 10       # Log every N epochs
  save_every: 50      # Save checkpoint every N epochs
  tqdm_silent: false  # Disable tqdm progress bars

training:
  use_amp: true      # Use automatic mixed precision
  dtype: float16      # float16 or bfloat16

# --- Parameters used when running with --full-sweep
# By default, only the parameters specified above are used
sweep:
  # Sweep grid for ViT architecture experiments
  param_grid:
    data.batch_size: [512]
    optim.epochs: [50, 100, 1000]
    model.use_projector: [false, true]
    model.type: [resnet, vit_s, vit_b]
    meta.seed: [1, 1000, 10000]
